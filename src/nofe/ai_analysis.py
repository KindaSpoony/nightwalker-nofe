# src/nofe/ai_analysis.py
import os
from pathlib import Path
from typing import Optional, Dict

SYSTEM_PROMPT = (
    "You are a senior OSINT analyst. Given a CHAOS report generated by NOFE, "
    "provide an executive analysis: identify the most important narratives, "
    "highlight geopolitical or economic risks, cross-reference entities, flag potential "
    "misinformation, and suggest follow-up questions. Be concise but insightful."
)

def load_report(report_path: str) -> str:
    return Path(report_path).read_text(encoding="utf-8")

def _get_api_key(cfg: Optional[Dict] = None) -> Optional[str]:
    return os.getenv("OPENAI_API_KEY") or (cfg or {}).get("openai_api_key")

def _chat_new_client(api_key: str, model: str, messages, temperature: float, max_tokens: int) -> str:
    # New OpenAI SDK (>=1.0): from openai import OpenAI
    from openai import OpenAI
    client = OpenAI(api_key=api_key)
    resp = client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=temperature,
        max_tokens=max_tokens,
    )
    return resp.choices[0].message.content.strip()

def _chat_legacy(api_key: str, model: str, messages, temperature: float, max_tokens: int) -> str:
    # Legacy SDK (<1.0): import openai
    import openai
    openai.api_key = api_key
    resp = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        temperature=temperature,
        max_tokens=max_tokens,
    )
    return resp["choices"][0]["message"]["content"].strip()

def generate_ai_analysis(report_text: str, cfg: Optional[Dict] = None) -> str:
    """
    Return AI analysis string. If no API key is available, return a skip message.
    """
    api_key = _get_api_key(cfg)
    if not api_key:
        return "AI analysis skipped: missing OPENAI_API_KEY."

    model = (cfg or {}).get("ai_model", "gpt-4o-mini")
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": report_text[:120000]},  # safety truncation
    ]

    # Try new client first; fall back to legacy if not installed.
    try:
        return _chat_new_client(api_key, model, messages, temperature=0.4, max_tokens=1000)
    except Exception:
        return _chat_legacy(api_key, model, messages, temperature=0.4, max_tokens=1000)

def main(report_path: str, output_path: str, cfg: Optional[Dict] = None):
    text = load_report(report_path)
    analysis = generate_ai_analysis(text, cfg=cfg)
    Path(output_path).write_text("# AI Analysis\n\n" + analysis + "\n", encoding="utf-8")

if __name__ == "__main__":
    import argparse, yaml
    parser = argparse.ArgumentParser()
    parser.add_argument("report_path")
    parser.add_argument("--output_path", default="")
    args = parser.parse_args()
    # Optional: pull cfg so ai_model / openai_api_key can be used locally
    base = Path(__file__).resolve().parent
    cfg_path = base / "config.yaml"
    cfg = yaml.safe_load(cfg_path.read_text(encoding="utf-8")) if cfg_path.exists() else {}
    out = args.output_path or args.report_path.replace("CHAOS_", "AI_CHAOS_")
    main(args.report_path, out, cfg=cfg)